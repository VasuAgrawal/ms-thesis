\chapter{Conclusions and Future Work}

This work comprises the development of three separate payloads and a scalable and flexible software system running on each payload capable of providing rapid situational awareness in the form of Artifact Localizations for the DARPA Subterranean Challenge. Each of the three payloads (drone, Mk. 0, and Mk. 1) contains a variety of sensors and sensing modalities which are fused to provide a single, globally consistent list of artifacts to a human operator at the base station in a robust and timely manner. This simulates information being reported first responders and emergency personnel during a disaster scenario, where rapid and accurate information about the environment is critical to saving lives and mitigating damage.

The complete system was tested during a number of field experiments, culminating in a series of deployments during the Tunnel Circuit of the DARPA Subterranean Challenge. We reported 25 out of 40 artifacts correctly between the two portals (Safety Research, Experimental), and won first place out of the 11 teams at the event. We also won an award for reporting the most accurate artifact, a backpack artifact reported during the second deployment in the Safety Research portal, with an error of 0.18m. Using the data collected at the Tunnel Circuit, we demonstrate the advantage of the fusion of multiple sensors and sensing modalities, which results in more artifacts being found, and being found more quickly, than is possible with any single sensor. 

Our results can be improved by addressing a number of problems with the current stack, described below. These changes, and many others, would improve the Artifact Localizations reported by the system and thus the quality of the situational awareness provided to future base station operators, including first responders and emergency personnel. We hope that our work may some day be used to reduce risk to human lives in dangerous situations underground.

\subsubsection{Hardware Synchronization}

Timestamps for individual sensor measurements are currently not synchronized to a single unified clock. Hardware synchronization for timestamps between all sensors in the payloads would result in a more consistent registration of sensor data to state estimates, eliminating the need for the State Estimate Delay Estimator and removing its inaccuracy. Jitter in timestamps for camera frames sent over USB would also be removed, since the exact time each frame was taken would be known, and would not need to be measured by arrival time. For the current sensor suite, full hardware synchronization can be added by timestamping trigger pulses from the RealSense cameras and PPS pulses from the IMU on the Xavier (or a separate microcontroller for the drone payload) via GPIO interrupts, and feeding PPS and camera trigger pulses into the Velodyne and thermal cameras respectively. Custom driver development is required to perform the timestamping and send the pulses, and to correlate the timestamps with data received over USB. The driver should be robust to frame drops over USB, which may be difficult without control over the firmware of the camera devices.

\subsubsection{Artifact 3D Modeling}

Coordinates for artifacts generated by the object detection localizer are found by taking the centroid of all points in the point clouds corresponding to each artifact. Even under the assumption that the generated point cloud is perfectly accurate and in the right position globally, this method will have an inherent error of between 10cm and 1m depending on the class of artifact since the point surveyed by DARPA is not exactly the centroid (see Figure \ref{tunnel artifacts}). Fitting 3D models of each artifact to the generated point clouds and using the models to determine the coordinates of the specified localization points could help remove this inherent error.

\subsubsection{Reduced False Positives}

The majority of the false positive artifacts reported to the base station stem from false positive bounding boxes coming from the object detectors. The detectors currently detect some real artifacts with low confidence, requiring a low threshold to ensure no artifacts are missed. However, this also lets through many false positive detections which get propagated through the pipeline and appear at the base station. Improving the quality of the dataset by having tighter bounding boxes and more background and viewpoint variation should help reduce false positives. Other object detection network architectures could also be explored provided they're able to run efficiently on the Xavier and NUC, such as YOLO \cite{redmon2018yolov3} or newer versions of MobileNet \cite{howard2019searching}. Larger object detection networks such as FasterRCNN \cite{ren2015faster}, networks which perform semantic segmentation, such as U-Net \cite{ronneberger2015u}, or those  which perform instance segmentation, such as MaskRCNN \cite{he2017mask}, may be able to offer more accurate and precise labels at the expense of slower than real time framerates. These labels could be propagated with a tracker to maintain real time framerates.

\subsubsection{Cell Phone Trilateration}

The current cell phone localization strategy is only able to localize cell phones which the robot directly drives past. This generates correct localizations in the tunnel circuit if the robot traverses the entire tunnel, but will fail if that is not the case. The experiment in Figure \ref{sensors_vs_full} shows the signal localizer had a final precision of $\frac{1}{3}$, indicating that it detected 3 distinct cell phones (39, 45, 59 in Figure \ref{tunnel_circuit_day_2}) but was only able to localize one of them (59). The localization accuracy can be improved by implementing cell phone trilateration utilizing either Bluetooth or WiFi RSSI values, such as in \cite{iglesias2012indoor}. The underlying RSSI to distance models work well in open spaces where line of sight is possible, but become more inaccurate as additional layers of structure (such as rock) are introduced. An environment aware algorithm which is able to vary the model parameters based on the surrounding environment parameters is likely to be necessary.

\subsubsection{Additional Sensors}

The sensor suite on the current payloads was selected specifically to detect artifacts for the Tunnel Circuit. The upcoming Urban Circuit introduces a gas artifact which cannot be detected with the current sensors \cite{urban_artifacts}. To handle the gas artifact, new sensors will need to be integrated into the payloads, and a new software module will be required to localize the gas artifact. The new module would produce Artifact Localization messages and feed into the Artifact Aggregator, just as the current Object Detection Localizer and Signal Localizer modules currently do. Other software modules could also be written to offer alternative ways to detect and localize artifacts with the existing sensor data, such as one which utilizes multi view stereo to localize artifacts detected in images without any depth information, or one which fuses audio information with signal readings to refine cell phone localizations.